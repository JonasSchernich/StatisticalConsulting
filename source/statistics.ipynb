{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cohort Statistics Analysis\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from preprocessing import DataLoader\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize DataLoader\n",
    "base_path = os.path.dirname(os.getcwd())\n",
    "loader = DataLoader(base_path)\n",
    "loader.load_all_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CohortStatistics:\n",
    "    def __init__(self, loader):\n",
    "        self.loader = loader\n",
    "        self.stats_df = pd.DataFrame()\n",
    "        \n",
    "    def calculate_basic_stats(self, pdata, name):\n",
    "        \"\"\"Calculate basic statistics for a cohort\"\"\"\n",
    "        stats = {\n",
    "            'cohort_name': name,\n",
    "            'patient_count': len(pdata)\n",
    "        }\n",
    "        \n",
    "        # Age statistics if available\n",
    "        if 'AGE' in pdata.columns:\n",
    "            # Convert to numeric, invalid values become NaN\n",
    "            age_data = pd.to_numeric(pdata['AGE'], errors='coerce').dropna()\n",
    "            if len(age_data) == 0:\n",
    "                stats.update({\n",
    "                    'min_age': np.nan,\n",
    "                    'q25_age': np.nan,\n",
    "                    'median_age': np.nan,\n",
    "                    'q75_age': np.nan,\n",
    "                    'max_age': np.nan\n",
    "                })\n",
    "            else:\n",
    "                stats.update({\n",
    "                    'min_age': float(age_data.min()),\n",
    "                    'q25_age': float(age_data.quantile(0.25)),\n",
    "                    'median_age': float(age_data.median()),\n",
    "                    'q75_age': float(age_data.quantile(0.75)),\n",
    "                    'max_age': float(age_data.max())\n",
    "                })\n",
    "        \n",
    "        # Tissue type if available\n",
    "        if 'TISSUE' in pdata.columns:\n",
    "            stats['tissue'] = pdata['TISSUE'].iloc[0] if not pdata['TISSUE'].isna().all() else np.nan\n",
    "            \n",
    "        return stats\n",
    "    \n",
    "\n",
    "    def calculate_stage_stats(self, pdata, column_name, stages):\n",
    "        \"\"\"Calculate statistics for different stages\"\"\"\n",
    "        stats = {}\n",
    "        \n",
    "        if column_name in pdata.columns:\n",
    "            stage_data = pdata[column_name]\n",
    "            if stage_data.isna().all():\n",
    "                for stage in stages:\n",
    "                    stats[f'count_{column_name}_{stage}'] = np.nan\n",
    "                    stats[f'prop_{column_name}_{stage}'] = np.nan\n",
    "            else:\n",
    "                total_stage = 0\n",
    "                for stage in stages:\n",
    "                    count = (stage_data == stage).sum()\n",
    "                    stats[f'count_{column_name}_{stage}'] = int(count)\n",
    "                    total_stage += count\n",
    "\n",
    "                for stage in stages:\n",
    "                    stats[f'prop_{column_name}_{stage}'] = (\n",
    "                        float(stats[f'count_{column_name}_{stage}'] / total_stage)\n",
    "                        if total_stage > 0 else 0\n",
    "                    )\n",
    "                    \n",
    "        return stats\n",
    "    \n",
    "    def calculate_gleason_stats(self, pdata):\n",
    "        \"\"\"Calculate Gleason score statistics\"\"\"\n",
    "        stats = {}\n",
    "        \n",
    "        if 'GLEASON_SCORE' in pdata.columns:\n",
    "            # Convert to numeric\n",
    "            gleason_data = pd.to_numeric(pdata['GLEASON_SCORE'], errors='coerce')\n",
    "            \n",
    "            if gleason_data.isna().all():\n",
    "                for score in range(2, 11):\n",
    "                    stats[f'gleason_{score}'] = np.nan\n",
    "                    stats[f'gleason_{score}_prop'] = np.nan\n",
    "            else:\n",
    "                total_gleason = 0\n",
    "                for score in range(2, 11):\n",
    "                    count = (gleason_data == score).sum()\n",
    "                    stats[f'gleason_{score}'] = int(count)\n",
    "                    total_gleason += count\n",
    "\n",
    "                for score in range(2, 11):\n",
    "                    stats[f'gleason_{score}_prop'] = (\n",
    "                        float(stats[f'gleason_{score}'] / total_gleason)\n",
    "                        if total_gleason > 0 else 0\n",
    "                    )\n",
    "            \n",
    "            # GLEASON_SCORE_1 and GLEASON_SCORE_2\n",
    "            for gs_column in ['GLEASON_SCORE_1', 'GLEASON_SCORE_2']:\n",
    "                if gs_column in pdata.columns:\n",
    "                    gs_data = pd.to_numeric(pdata[gs_column], errors='coerce')\n",
    "                    \n",
    "                    if gs_data.isna().all():\n",
    "                        for score in range(1, 6):\n",
    "                            stats[f'{gs_column}_{score}'] = np.nan\n",
    "                            stats[f'{gs_column}_{score}_prop'] = np.nan\n",
    "                    else:\n",
    "                        total_gs = 0\n",
    "                        for score in range(1, 6):\n",
    "                            count = (gs_data == score).sum()\n",
    "                            stats[f'{gs_column}_{score}'] = int(count)\n",
    "                            total_gs += count\n",
    "\n",
    "                        for score in range(1, 6):\n",
    "                            stats[f'{gs_column}_{score}_prop'] = (\n",
    "                                float(stats[f'{gs_column}_{score}'] / total_gs)\n",
    "                                if total_gs > 0 else 0\n",
    "                            )\n",
    "                        \n",
    "        return stats\n",
    "    \n",
    "    def calculate_psa_stats(self, pdata):\n",
    "        \"\"\"Calculate PSA-related statistics\"\"\"\n",
    "        stats = {}\n",
    "        \n",
    "        if 'PRE_OPERATIVE_PSA' in pdata.columns:\n",
    "            # Convert to numeric, invalid values become NaN\n",
    "            psa_data = pd.to_numeric(pdata['PRE_OPERATIVE_PSA'], errors='coerce').dropna()\n",
    "            if len(psa_data) == 0:\n",
    "                stats.update({\n",
    "                    'psa_mean': np.nan,\n",
    "                    'psa_median': np.nan,\n",
    "                    'psa_min': np.nan,\n",
    "                    'psa_max': np.nan,\n",
    "                    'psa_q25': np.nan,\n",
    "                    'psa_q75': np.nan,\n",
    "                    'psa_over_4_count': np.nan,\n",
    "                    'psa_over_4_prop': np.nan\n",
    "                })\n",
    "            else:\n",
    "                stats.update({\n",
    "                    'psa_mean': float(psa_data.mean()),\n",
    "                    'psa_median': float(psa_data.median()),\n",
    "                    'psa_min': float(psa_data.min()),\n",
    "                    'psa_max': float(psa_data.max()),\n",
    "                    'psa_q25': float(psa_data.quantile(0.25)),\n",
    "                    'psa_q75': float(psa_data.quantile(0.75)),\n",
    "                    'psa_over_4_count': int((psa_data > 4).sum()),\n",
    "                    'psa_over_4_prop': float((psa_data > 4).sum() / len(psa_data))\n",
    "                })\n",
    "                \n",
    "        return stats\n",
    "    \n",
    "    def calculate_bcr_stats(self, pdata):\n",
    "        \"\"\"Calculate BCR-related statistics\"\"\"\n",
    "        stats = {}\n",
    "        \n",
    "        if all(col in pdata.columns for col in ['BCR_STATUS', 'MONTH_TO_BCR']):\n",
    "            # Convert both columns to numeric\n",
    "            bcr_status = pd.to_numeric(pdata['BCR_STATUS'], errors='coerce')\n",
    "            month_to_bcr = pd.to_numeric(pdata['MONTH_TO_BCR'], errors='coerce')\n",
    "            \n",
    "            # Get valid BCR data\n",
    "            bcr_data = month_to_bcr[bcr_status == 1].dropna()\n",
    "            \n",
    "            if len(bcr_data) == 0:\n",
    "                stats.update({\n",
    "                    'bcr_mean': np.nan,\n",
    "                    'bcr_median': np.nan,\n",
    "                    'bcr_min': np.nan,\n",
    "                    'bcr_max': np.nan,\n",
    "                    'bcr_q25': np.nan,\n",
    "                    'bcr_q75': np.nan,\n",
    "                    'bcr_proportion': np.nan\n",
    "                })\n",
    "            else:\n",
    "                stats.update({\n",
    "                    'bcr_mean': float(bcr_data.mean()),\n",
    "                    'bcr_median': float(bcr_data.median()),\n",
    "                    'bcr_min': float(bcr_data.min()),\n",
    "                    'bcr_max': float(bcr_data.max()),\n",
    "                    'bcr_q25': float(bcr_data.quantile(0.25)),\n",
    "                    'bcr_q75': float(bcr_data.quantile(0.75))\n",
    "                })\n",
    "                \n",
    "                # Calculate BCR proportion using non-NA BCR_STATUS values\n",
    "                valid_bcr = bcr_status.dropna()\n",
    "                if len(valid_bcr) > 0:\n",
    "                    bcr_count = (valid_bcr == 1).sum()\n",
    "                    stats['bcr_proportion'] = float(bcr_count / len(valid_bcr))\n",
    "                else:\n",
    "                    stats['bcr_proportion'] = np.nan\n",
    "                \n",
    "        return stats\n",
    "\n",
    "    \n",
    "    def calculate_gene_stats(self, exprs_data):\n",
    "        \"\"\"Calculate gene-related statistics\"\"\"\n",
    "        return {\n",
    "            'gene_count': exprs_data.shape[1] if isinstance(exprs_data, pd.DataFrame) else np.nan\n",
    "        }\n",
    "    \n",
    "    def calculate_cohort_stats(self, pdata, exprs_data, name):\n",
    "        \"\"\"Calculate all statistics for a single cohort\"\"\"\n",
    "        # Initialize with basic stats\n",
    "        stats = self.calculate_basic_stats(pdata, name)\n",
    "        \n",
    "        # T-stages to check\n",
    "        t_stages = ['T1', 'T1A', 'T1B', 'T1C', 'T2', 'T2A', 'T2B', 'T2C', 'T3', 'T3A', 'T3B', 'T4']\n",
    "        \n",
    "        # Add all other statistics\n",
    "        stats.update(self.calculate_stage_stats(pdata, 'PATH_T_STAGE', t_stages))\n",
    "        stats.update(self.calculate_stage_stats(pdata, 'CLIN_T_STAGE', t_stages))\n",
    "        stats.update(self.calculate_gleason_stats(pdata))\n",
    "        stats.update(self.calculate_psa_stats(pdata))\n",
    "        stats.update(self.calculate_bcr_stats(pdata))\n",
    "        stats.update(self.calculate_gene_stats(exprs_data))\n",
    "        \n",
    "        return stats\n",
    "    \n",
    "    def calculate_all_stats(self):\n",
    "        \"\"\"Calculate statistics for all cohorts\"\"\"\n",
    "        all_stats = []\n",
    "        \n",
    "        # For original cohort data\n",
    "        for name, pdata in self.loader.pdata_original.items():\n",
    "            exprs = self.loader.exprs_data.get(name.replace('cohort_', 'exprs_'), pd.DataFrame())\n",
    "            stats = self.calculate_cohort_stats(pdata, exprs, f\"Original_{name}\")\n",
    "            all_stats.append(stats)\n",
    "            \n",
    "        # For imputed cohort data\n",
    "        for name, pdata in self.loader.pdata_imputed.items():\n",
    "            exprs = self.loader.exprs_data.get(name.replace('cohort_', 'exprs_'), pd.DataFrame())\n",
    "            stats = self.calculate_cohort_stats(pdata, exprs, f\"Imputed_{name}\")\n",
    "            all_stats.append(stats)\n",
    "            \n",
    "        # For merged data\n",
    "        if self.loader.merged_pdata_original:\n",
    "            for name, pdata in self.loader.merged_pdata_original.items():\n",
    "                stats = self.calculate_cohort_stats(\n",
    "                    pdata, \n",
    "                    self.loader.intersection_data.get('exprs_intersect.csv', pd.DataFrame()),\n",
    "                    f\"Merged_Original_{name}\"\n",
    "                )\n",
    "                all_stats.append(stats)\n",
    "                \n",
    "        if self.loader.merged_pdata_imputed:\n",
    "            for name, pdata in self.loader.merged_pdata_imputed.items():\n",
    "                stats = self.calculate_cohort_stats(\n",
    "                    pdata, \n",
    "                    self.loader.common_genes_data.get('common_genes_knn_imputed.csv', pd.DataFrame()),\n",
    "                    f\"Merged_Imputed_{name}\"\n",
    "                )\n",
    "                all_stats.append(stats)\n",
    "        \n",
    "        self.stats_df = pd.DataFrame(all_stats)\n",
    "        return self.stats_df\n",
    "    \n",
    "    def plot_cohort_comparisons(self):\n",
    "        \"\"\"Create plots comparing key statistics across cohorts\"\"\"\n",
    "        if self.stats_df.empty:\n",
    "            self.calculate_all_stats()\n",
    "            \n",
    "        plt.style.use('seaborn')\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(20, 20))\n",
    "        \n",
    "        # Helper function to plot with NA handling\n",
    "        def safe_barplot(data, x, y, ax, title):\n",
    "            plot_data = data.copy()\n",
    "            plot_data[y] = pd.to_numeric(plot_data[y], errors='coerce')\n",
    "            if plot_data[y].notna().any():\n",
    "                sns.barplot(data=plot_data, x=x, y=y, ax=ax)\n",
    "                ax.set_title(title)\n",
    "                ax.tick_params(axis='x', rotation=45)\n",
    "            else:\n",
    "                ax.text(0.5, 0.5, f'No data available for {y}', \n",
    "                       horizontalalignment='center', verticalalignment='center')\n",
    "        \n",
    "        # Plot all comparisons\n",
    "        safe_barplot(self.stats_df, 'cohort_name', 'patient_count', axes[0,0], 'Patient Count by Cohort')\n",
    "        safe_barplot(self.stats_df, 'cohort_name', 'bcr_proportion', axes[0,1], 'BCR Proportion by Cohort')\n",
    "        safe_barplot(self.stats_df, 'cohort_name', 'gene_count', axes[1,0], 'Gene Count by Cohort')\n",
    "        safe_barplot(self.stats_df, 'cohort_name', 'median_age', axes[1,1], 'Median Age by Cohort')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  cohort_name  patient_count  min_age  \\\n",
      "0              Original_Belfast_2018_Jain.csv            248  48.0000   \n",
      "1           Original_CPC_GENE_2017_Fraser.csv             73  43.8500   \n",
      "2            Original_DKFZ_2018_Gerhauser.csv             82  32.0000   \n",
      "3            Original_CancerMap_2017_Luca.csv            133      NaN   \n",
      "4              Original_MSKCC_2010_Taylor.csv            131  37.2958   \n",
      "5              Original_Atlanta_2014_Long.csv            100  43.0000   \n",
      "6         Original_CamCap_2016_Ross_Adams.csv            112  41.0000   \n",
      "7      Original_Stockholm_2016_Ross_Adams.csv             92      NaN   \n",
      "8                  Original_CPGEA_2020_Li.csv            120  50.0000   \n",
      "9               Imputed_Belfast_2018_Jain.csv            248  48.0000   \n",
      "10           Imputed_CPC_GENE_2017_Fraser.csv             73  43.8500   \n",
      "11            Imputed_DKFZ_2018_Gerhauser.csv             82  32.0000   \n",
      "12            Imputed_CancerMap_2017_Luca.csv            133      NaN   \n",
      "13              Imputed_MSKCC_2010_Taylor.csv            131  37.2958   \n",
      "14              Imputed_Atlanta_2014_Long.csv            100  43.0000   \n",
      "15         Imputed_CamCap_2016_Ross_Adams.csv            112  41.0000   \n",
      "16      Imputed_Stockholm_2016_Ross_Adams.csv             92      NaN   \n",
      "17                  Imputed_CPGEA_2020_Li.csv            120  50.0000   \n",
      "18  Merged_Original_merged_original_pData.csv           1091  32.0000   \n",
      "19    Merged_Imputed_merged_imputed_pData.csv           1091  32.0000   \n",
      "\n",
      "     q25_age  median_age    q75_age  max_age        tissue  \\\n",
      "0   63.00000   68.000000  72.000000    79.00          FFPE   \n",
      "1   56.64000   60.540000  64.260000    72.02  Fresh_frozen   \n",
      "2   45.25000   47.500000  49.000000    52.00  Fresh_frozen   \n",
      "3        NaN         NaN        NaN      NaN  Fresh_frozen   \n",
      "4   53.53297   57.994390  62.110840    83.00  Fresh_frozen   \n",
      "5   56.79589   61.654795  65.979452    78.00          FFPE   \n",
      "6   56.00000   62.000000  65.000000    73.00  Fresh_frozen   \n",
      "7        NaN         NaN        NaN      NaN  Fresh_frozen   \n",
      "8   65.00000   69.000000  74.000000    88.00   Snap_frozen   \n",
      "9   63.00000   68.000000  72.000000    79.00           NaN   \n",
      "10  56.64000   60.540000  64.260000    72.02           NaN   \n",
      "11  45.25000   47.500000  49.000000    52.00           NaN   \n",
      "12       NaN         NaN        NaN      NaN           NaN   \n",
      "13  53.53297   57.994390  62.110840    83.00           NaN   \n",
      "14  56.79589   61.654795  65.979452    78.00           NaN   \n",
      "15  56.00000   62.000000  65.000000    73.00           NaN   \n",
      "16       NaN         NaN        NaN      NaN           NaN   \n",
      "17  65.00000   69.000000  74.000000    88.00           NaN   \n",
      "18  56.00000   63.000000  68.941336    88.00          FFPE   \n",
      "19  55.00000   62.000000  67.700280    88.00          FFPE   \n",
      "\n",
      "    count_PATH_T_STAGE_T1  prop_PATH_T_STAGE_T1  ...  psa_over_4_count  \\\n",
      "0                     NaN                   NaN  ...               247   \n",
      "1                     0.0                   0.0  ...                65   \n",
      "2                     0.0                   0.0  ...                79   \n",
      "3                     0.0                   0.0  ...               122   \n",
      "4                     0.0                   0.0  ...               107   \n",
      "5                     0.0                   0.0  ...                88   \n",
      "6                     0.0                   0.0  ...               108   \n",
      "7                     0.0                   0.0  ...                82   \n",
      "8                     0.0                   0.0  ...               115   \n",
      "9                     NaN                   NaN  ...               247   \n",
      "10                    0.0                   0.0  ...                65   \n",
      "11                    0.0                   0.0  ...                79   \n",
      "12                    0.0                   0.0  ...               124   \n",
      "13                    0.0                   0.0  ...               108   \n",
      "14                    0.0                   0.0  ...                91   \n",
      "15                    0.0                   0.0  ...               109   \n",
      "16                    0.0                   0.0  ...                84   \n",
      "17                    0.0                   0.0  ...               115   \n",
      "18                    0.0                   0.0  ...              1013   \n",
      "19                    0.0                   0.0  ...              1024   \n",
      "\n",
      "    psa_over_4_prop   bcr_mean  bcr_median  bcr_min  bcr_max  bcr_q25  \\\n",
      "0          0.995968  58.910714      59.000   10.000  106.000   39.500   \n",
      "1          0.890411  29.874750      24.575    1.643   90.086   11.548   \n",
      "2          0.963415   9.111111       3.900    0.500   37.100    1.375   \n",
      "3          0.931298  24.666667      18.000    1.000   66.000   11.750   \n",
      "4          0.823077  25.547407      18.830    1.380   92.980    4.830   \n",
      "5          0.907216  23.612245      18.279    0.000  154.225    1.578   \n",
      "6          0.972973  17.999105      16.044    0.756   57.370    4.471   \n",
      "7          0.911111  23.469556      19.299    0.362   98.268    1.808   \n",
      "8          0.974576  12.642857       4.000    0.000   73.000    1.500   \n",
      "9          0.995968  58.910714      59.000   10.000  106.000   39.500   \n",
      "10         0.890411  29.874750      24.575    1.643   90.086   11.548   \n",
      "11         0.963415   9.111111       3.900    0.500   37.100    1.375   \n",
      "12         0.932331  24.666667      18.000    1.000   66.000   11.750   \n",
      "13         0.824427  25.547407      18.830    1.380   92.980    4.830   \n",
      "14         0.910000  23.612245      18.279    0.000  154.225    1.578   \n",
      "15         0.973214  17.999105      16.044    0.756   57.370    4.471   \n",
      "16         0.913043  23.469556      19.299    0.362   98.268    1.808   \n",
      "17         0.974576  12.642857       4.000    0.000   73.000    1.500   \n",
      "18         0.937963  28.293651      20.000    0.000  154.225    4.000   \n",
      "19         0.938588  28.293651      20.000    0.000  154.225    4.000   \n",
      "\n",
      "    bcr_q75  bcr_proportion  gene_count  \n",
      "0   80.2500        0.225806       16810  \n",
      "1   34.7515        0.219178       35250  \n",
      "2   12.7250        0.219512       17654  \n",
      "3   38.2500        0.270677       45286  \n",
      "4   33.5750        0.206107       45286  \n",
      "5   29.8330        0.490000       49826  \n",
      "6   21.6820        0.169643       19953  \n",
      "7   36.5920        0.489130       19955  \n",
      "8   15.5000        0.291667       26494  \n",
      "9   80.2500        0.225806       16810  \n",
      "10  34.7515        0.219178       35250  \n",
      "11  12.7250        0.219512       17654  \n",
      "12  38.2500        0.270677       45286  \n",
      "13  33.5750        0.206107       45286  \n",
      "14  29.8330        0.490000       49826  \n",
      "15  21.6820        0.169643       19953  \n",
      "16  36.5920        0.489130       19955  \n",
      "17  15.5000        0.291667       26494  \n",
      "18  42.8050        0.275894       13214  \n",
      "19  42.8050        0.275894       15495  \n",
      "\n",
      "[20 rows x 110 columns]\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "stats_calculator = CohortStatistics(loader)\n",
    "stats_df = stats_calculator.calculate_all_stats()\n",
    "print(stats_df)\n",
    "# comparison_plots = stats_calculator.plot_cohort_comparisons()\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
